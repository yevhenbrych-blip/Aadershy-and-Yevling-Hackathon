{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ca6f8b",
   "metadata": {},
   "source": [
    "# Drift vs Lipid Dynamics – Final Runnable Pipeline\n",
    "\n",
    "This notebook contains the **complete, runnable pipeline**:\n",
    "1. Drift detection using boundary alignment residuals\n",
    "2. PCA on contour features (only if drift is not dominant)\n",
    "\n",
    "You only need to provide your existing AFM helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a689a2db",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fcc8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from scipy.ndimage import shift as ndi_shift\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import gwyfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color\n",
    "from skimage.feature import match_template\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes, binary_opening, binary_closing, disk\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "from scipy.spatial import ConvexHull\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ac644",
   "metadata": {},
   "source": [
    "### Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3057eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loading_data(data_count,plot=True):\n",
    "    path = 'C:/Users/yevhe/Desktop/Hackathon/Feature detection/Domain evolution data/Raw data/'\n",
    "    image = '%s.gwy' % data_count\n",
    "\n",
    "    obj = gwyfile.load(path+image)\n",
    "    channel = obj['/0/data']['data']\n",
    "    yres = obj['/0/data']['yres']\n",
    "    xres = obj['/0/data']['xres']\n",
    "    raw_height = channel.reshape((yres, xres))\n",
    "\n",
    "    if plot:\n",
    "        im = plt.imshow(raw_height, cmap='gray')\n",
    "        plt.title(\"Raw data file\")\n",
    "        plt.colorbar(im, fraction=0.046)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return raw_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca300d",
   "metadata": {},
   "source": [
    "# Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0746c8b4",
   "metadata": {},
   "source": [
    "### Level data by mean plane subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34082d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_plane_subtraction(Z, mask=None, plot=True):\n",
    "    \"\"\"\n",
    "    Fit plane z = ax + by + c (least squares) and subtract it.\n",
    "    mask: optional boolean array; True pixels are used for fitting the plane.\n",
    "    plot: if True, shows original, fitted plane, and levelled result.\n",
    "    \"\"\"\n",
    "    Z = Z.astype(float)\n",
    "    ny, nx = Z.shape\n",
    "    yy, xx = np.indices(Z.shape)\n",
    "\n",
    "    if mask is None:\n",
    "        x = xx.ravel()\n",
    "        y = yy.ravel()\n",
    "        z = Z.ravel()\n",
    "    else:\n",
    "        m = mask.astype(bool)\n",
    "        x = xx[m].ravel()\n",
    "        y = yy[m].ravel()\n",
    "        z = Z[m].ravel()\n",
    "\n",
    "    # Least squares solve for [a, b, c]\n",
    "    A = np.column_stack([x, y, np.ones_like(x)])\n",
    "    coeff, *_ = np.linalg.lstsq(A, z, rcond=None)\n",
    "    a, b, c = coeff\n",
    "\n",
    "    plane = a * xx + b * yy + c\n",
    "    Z_level = Z - plane\n",
    "\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        im0 = axs[0].imshow(Z, cmap=\"viridis\"); axs[0].set_title(\"Original\")\n",
    "        im1 = axs[1].imshow(plane, cmap=\"viridis\"); axs[1].set_title(\"Fitted mean plane\")\n",
    "        im2 = axs[2].imshow(Z_level, cmap=\"viridis\"); axs[2].set_title(\"Levelled (mean plane sub.)\")\n",
    "        for ax in axs:\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "        plt.colorbar(im0, ax=axs[0], fraction=0.046)\n",
    "        plt.colorbar(im1, ax=axs[1], fraction=0.046)\n",
    "        plt.colorbar(im2, ax=axs[2], fraction=0.046)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return Z_level, plane, (a, b, c)\n",
    "\n",
    "#Z_level, plane, coeffs = mean_plane_subtraction(raw_height, plot=True)\n",
    "#print(\"Plane coeffs (a,b,c):\", coeffs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e303a",
   "metadata": {},
   "source": [
    "### Flattening the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30e396bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_flatten_rows(h, order=1,plot=True):\n",
    "    h = np.asarray(h)\n",
    "    ny, nx = h.shape\n",
    "    x = np.arange(nx)\n",
    "    out = np.empty_like(h, dtype=float)\n",
    "\n",
    "    for i in range(ny):\n",
    "        coeff = np.polyfit(x, h[i, :], order)\n",
    "        baseline = np.polyval(coeff, x)\n",
    "        out[i, :] = h[i, :] - baseline\n",
    "    \n",
    "    if plot:\n",
    "        im = plt.imshow(out, cmap='gray')\n",
    "        plt.title(\"Polynomial flattened image\")\n",
    "        plt.colorbar(im, fraction=0.046)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return out\n",
    "\n",
    "\n",
    "  # “horizontal” style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d04f3f",
   "metadata": {},
   "source": [
    "### Level data by fitting plane through 3 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e3d39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def level_by_3_points(Z, p1, p2, p3, show_plane=False,plot=True):\n",
    "    \"\"\"\n",
    "    Level a height image by fitting a plane through 3 points\n",
    "    and plot reference points for visual validation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Z : 2D numpy array\n",
    "        Height image\n",
    "    p1, p2, p3 : (x, y)\n",
    "        Pixel coordinates of reference points (x = column, y = row)\n",
    "    show_plane : bool\n",
    "        If True, also plot the fitted plane\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Z_level : 2D numpy array\n",
    "        Levelled height image\n",
    "    plane : 2D numpy array\n",
    "        Fitted plane\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack points\n",
    "    (x1, y1), (x2, y2), (x3, y3) = p1, p2, p3\n",
    "\n",
    "    # Heights at points\n",
    "    z1 = Z[int(round(y1)), int(round(x1))]\n",
    "    z2 = Z[int(round(y2)), int(round(x2))]\n",
    "    z3 = Z[int(round(y3)), int(round(x3))]\n",
    "\n",
    "    # Solve plane: z = a*x + b*y + c\n",
    "    A = np.array([[x1, y1, 1],\n",
    "                  [x2, y2, 1],\n",
    "                  [x3, y3, 1]], dtype=float)\n",
    "    b = np.array([z1, z2, z3], dtype=float)\n",
    "\n",
    "    a, bcoef, c = np.linalg.solve(A, b)\n",
    "\n",
    "    yy, xx = np.indices(Z.shape)\n",
    "    plane = a * xx + bcoef * yy + c\n",
    "\n",
    "    Z_level = Z - plane\n",
    "\n",
    "    # -----------------------------\n",
    "    # Plotting\n",
    "    if plot:\n",
    "        # -----------------------------\n",
    "        fig, axs = plt.subplots(1, 2 + int(show_plane), figsize=(12, 4))\n",
    "\n",
    "        # Original image with points\n",
    "        im0 = axs[0].imshow(Z, cmap='viridis')\n",
    "        axs[0].scatter([x1, x2, x3], [y1, y2, y3],\n",
    "                    c='red', s=60, marker='x', label='Reference points')\n",
    "        axs[0].set_title(\"Original image\")\n",
    "        axs[0].legend()\n",
    "        plt.colorbar(im0, ax=axs[0], fraction=0.046)\n",
    "\n",
    "        # Levelled image\n",
    "        im1 = axs[1].imshow(Z_level, cmap='gray')\n",
    "        axs[1].set_title(\"Levelled image (3-point plane)\")\n",
    "        plt.colorbar(im1, ax=axs[1], fraction=0.046)\n",
    "\n",
    "        # Optional plane plot\n",
    "        if show_plane:\n",
    "            im2 = axs[2].imshow(plane, cmap='viridis')\n",
    "            axs[2].set_title(\"Fitted plane\")\n",
    "            plt.colorbar(im2, ax=axs[2], fraction=0.046)\n",
    "\n",
    "        for ax in axs:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return Z_level, plane\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272fd706",
   "metadata": {},
   "source": [
    "### Conveting the image to binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde734d",
   "metadata": {},
   "source": [
    "### Croping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0feaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- crop helpers (keep yours if already defined) ---\n",
    "def center_crop(img, crop_size=80):\n",
    "    h, w = img.shape\n",
    "    start_row = (h - crop_size) // 2\n",
    "    start_col = (w - crop_size) // 2\n",
    "    return img[start_row:start_row + crop_size, start_col:start_col + crop_size]\n",
    "\n",
    "def random_crop(img, crop_size=80, rng=None):\n",
    "    h, w = img.shape\n",
    "    max_row = h - crop_size\n",
    "    max_col = w - crop_size\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    r0 = rng.integers(0, max_row + 1)\n",
    "    c0 = rng.integers(0, max_col + 1)\n",
    "    return img[r0:r0 + crop_size, c0:c0 + crop_size], (int(r0), int(c0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be5eddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binary(Z_level,plot=True):\n",
    "\n",
    "    # --- 1) Build 1D array for histogram/thresholding ---\n",
    "    h = Z_level.astype(float).ravel()\n",
    "\n",
    "    lo, hi = np.percentile(h, [0.5, 99.5])\n",
    "    h_clip = h[(h > lo) & (h < hi)]\n",
    "\n",
    "    # --- 2) Otsu on clipped distribution ---\n",
    "    thr = threshold_otsu(h_clip)\n",
    "    #print(f\"Otsu threshold (on clipped data): {thr:.3f} nm\")\n",
    "\n",
    "    # --- 3) Threshold full image ---\n",
    "    mask = Z_level > thr\n",
    "\n",
    "    # --- 4) Clean mask ---\n",
    "    mask = remove_small_objects(mask, min_size=200)\n",
    "    mask = remove_small_holes(mask, area_threshold=200)\n",
    "    mask = binary_opening(mask, disk(1))\n",
    "    mask = binary_closing(mask, disk(2))\n",
    "    if plot:\n",
    "        # --- 5) Main figure: histogram | image+contour | mask ---\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(\n",
    "            1, 3, figsize=(14, 4),\n",
    "            gridspec_kw=dict(width_ratios=[1, 1.2, 1])\n",
    "        )\n",
    "\n",
    "        # Histogram\n",
    "        ax1.hist(h_clip, bins=200)\n",
    "        ax1.axvline(thr, color='red', linestyle='--', linewidth=2,\n",
    "                    label=f'Otsu = {thr:.3f} nm')\n",
    "        ax1.set_xlabel(\"Height (nm)\")\n",
    "        ax1.set_ylabel(\"Count\")\n",
    "        ax1.legend()\n",
    "\n",
    "        # Image + contour\n",
    "        ax2.imshow(Z_level, cmap='gray')\n",
    "        ax2.contour(mask, levels=[0.5], colors='r', linewidths=1)\n",
    "        ax2.set_title(\"Levelled image + mask boundary\")\n",
    "        ax2.axis('off')\n",
    "\n",
    "        # Binary mask\n",
    "        ax3.imshow(mask, cmap='gray')\n",
    "        ax3.set_title(\"Binary mask (cleaned)\")\n",
    "        ax3.axis('off')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return mask, thr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209c85b",
   "metadata": {},
   "source": [
    "# Statisitics on the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343bff9",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215cbb07",
   "metadata": {},
   "source": [
    "### Executing the data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4adef75c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contour_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m center_img \u001b[38;5;241m=\u001b[39m center_crop(leveled_3p, crop_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m     25\u001b[0m mask_c \u001b[38;5;241m=\u001b[39m plot_binary(center_img, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 26\u001b[0m stats_c, _ \u001b[38;5;241m=\u001b[39m contour_stats(mask_c, pixel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stats_c\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     29\u001b[0m     stats_c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_count\n",
      "\u001b[1;31mNameError\u001b[0m: name 'contour_stats' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# --- your file selection ---\n",
    "data_list = ['1','2','3','4','5','6','7','8']\n",
    "\n",
    "rows = []\n",
    "rng = np.random.default_rng(0)       # reproducible random crops\n",
    "n_random_per_frame = 5               # set to 1 if you only want one random crop each\n",
    "\n",
    "for data_count in data_list:\n",
    "    raw_height = Loading_data(data_count, plot=False)\n",
    "    Z_level, plane, coeffs = mean_plane_subtraction(raw_height, plot=False)\n",
    "    flattened = poly_flatten_rows(Z_level, order=0, plot=False)\n",
    "    leveled_3p, plane = level_by_3_points(\n",
    "        flattened, p1=(10, 20), p2=(25, 50), p3=(30, 90),\n",
    "        show_plane=True, plot=False\n",
    "    )\n",
    "\n",
    "    # ----------------\n",
    "    # CENTER crop stats\n",
    "    # ----------------\n",
    "    center_img = center_crop(leveled_3p, crop_size=80)\n",
    "    mask_c = plot_binary(center_img, plot=False)[0]\n",
    "    stats_c, _ = contour_stats(mask_c, pixel_size=None)\n",
    "\n",
    "    if stats_c.get(\"ok\", False):\n",
    "        stats_c[\"count\"] = data_count\n",
    "        stats_c[\"crop_type\"] = \"center\"\n",
    "        stats_c[\"rep\"] = 0                  # always 0 for center\n",
    "        stats_c[\"crop_r0\"] = 10             # 100->80 center crop fixed offset\n",
    "        stats_c[\"crop_c0\"] = 10\n",
    "        rows.append(stats_c)\n",
    "\n",
    "    # ----------------\n",
    "    # RANDOM crop stats (repeatable)\n",
    "    # ----------------\n",
    "    for rep in range(n_random_per_frame):\n",
    "        rand_img, (r0, c0) = random_crop(leveled_3p, crop_size=80, rng=rng)\n",
    "        mask_r = plot_binary(rand_img, plot=False)[0]\n",
    "        stats_r, _ = contour_stats(mask_r, pixel_size=None)\n",
    "\n",
    "        if not stats_r.get(\"ok\", False):\n",
    "            continue\n",
    "\n",
    "        stats_r[\"count\"] = data_count\n",
    "        stats_r[\"crop_type\"] = \"random\"\n",
    "        stats_r[\"rep\"] = rep\n",
    "        stats_r[\"crop_r0\"] = r0\n",
    "        stats_r[\"crop_c0\"] = c0\n",
    "        rows.append(stats_r)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Multi-index makes splitting super easy later\n",
    "df = df.set_index([\"count\", \"crop_type\", \"rep\"]).sort_index()\n",
    "\n",
    "print(df.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f2859",
   "metadata": {},
   "source": [
    "## Alignment and residual feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mask_to_boundary(mask):\n",
    "    mask = mask.astype(bool)\n",
    "    return (mask ^ binary_erosion(mask)).astype(float)\n",
    "\n",
    "def estimate_shift(ref_img, mov_img, upsample_factor=10):\n",
    "    shift_rc, error, _ = phase_cross_correlation(\n",
    "        ref_img, mov_img, upsample_factor=upsample_factor\n",
    "    )\n",
    "    return shift_rc, float(error)\n",
    "\n",
    "def residual_after_translation(mask_ref, mask_mov):\n",
    "    ref = mask_to_boundary(mask_ref)\n",
    "    mov = mask_to_boundary(mask_mov)\n",
    "\n",
    "    shift_rc, pc_error = estimate_shift(ref, mov)\n",
    "\n",
    "    mov_aligned = ndi_shift(\n",
    "        mov, shift=shift_rc, order=0, mode=\"constant\", cval=0.0\n",
    "    )\n",
    "\n",
    "    ref_b = ref > 0.5\n",
    "    mov_b = mov_aligned > 0.5\n",
    "\n",
    "    mismatch = np.logical_xor(ref_b, mov_b).mean()\n",
    "    inter = np.logical_and(ref_b, mov_b).sum()\n",
    "    union = np.logical_or(ref_b, mov_b).sum()\n",
    "    iou = inter / union if union else 1.0\n",
    "\n",
    "    return {\n",
    "        \"shift_row\": float(shift_rc[0]),\n",
    "        \"shift_col\": float(shift_rc[1]),\n",
    "        \"phasecorr_error\": float(pc_error),\n",
    "        \"boundary_mismatch\": float(mismatch),\n",
    "        \"boundary_iou\": float(iou),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc026059",
   "metadata": {},
   "source": [
    "## Crop utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def center_crop(img, crop_size=80):\n",
    "    h, w = img.shape\n",
    "    s = (h - crop_size) // 2\n",
    "    return img[s:s+crop_size, s:s+crop_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d58e1",
   "metadata": {},
   "source": [
    "## Build masks from AFM frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b90107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_center_masks(data_list):\n",
    "    masks = []\n",
    "    for idx in data_list:\n",
    "        raw = Loading_data(idx, plot=False)\n",
    "        Z, *_ = mean_plane_subtraction(raw, plot=False)\n",
    "        Z = poly_flatten_rows(Z, order=0, plot=False)\n",
    "        Z, _ = level_by_3_points(Z, (10,20),(25,50),(30,90), plot=False)\n",
    "\n",
    "        crop = center_crop(Z, 80)\n",
    "        mask = plot_binary(crop, plot=False)[0]\n",
    "        masks.append(mask)\n",
    "    return masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4940662",
   "metadata": {},
   "source": [
    "## Drift feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72682d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drift_features_from_masks(masks):\n",
    "    rows = []\n",
    "    for i in range(1, len(masks)):\n",
    "        feats = residual_after_translation(masks[i-1], masks[i])\n",
    "        feats[\"frame\"] = i\n",
    "        rows.append(feats)\n",
    "    return pd.DataFrame(rows).set_index(\"frame\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682736d",
   "metadata": {},
   "source": [
    "## Drift diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_drift_diagnostics(df):\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot(df.index, df[\"shift_row\"], \"-o\", label=\"Δrow\")\n",
    "    plt.plot(df.index, df[\"shift_col\"], \"-o\", label=\"Δcol\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"Shift (px)\")\n",
    "    plt.title(\"Estimated drift per frame\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(df[\"boundary_iou\"], df[\"boundary_mismatch\"], s=60, edgecolor=\"k\")\n",
    "    plt.xlabel(\"Boundary IoU\")\n",
    "    plt.ylabel(\"Boundary mismatch\")\n",
    "    plt.title(\"Alignment residual space\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c072a25",
   "metadata": {},
   "source": [
    "## Drift gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drift_gate(df, iou_thresh=0.9, mismatch_thresh=0.08, frac_thresh=0.6):\n",
    "    drift_like = (\n",
    "        (df[\"boundary_iou\"] >= iou_thresh) &\n",
    "        (df[\"boundary_mismatch\"] <= mismatch_thresh)\n",
    "    )\n",
    "    frac = drift_like.mean() if len(df) else 0.0\n",
    "    return frac >= frac_thresh, frac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a7f53",
   "metadata": {},
   "source": [
    "## PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_pca(df, index_col=\"count\"):\n",
    "    df2 = df.copy()\n",
    "    if index_col in df2.columns:\n",
    "        df2 = df2.set_index(index_col)\n",
    "\n",
    "    X = df2.select_dtypes(include=[np.number])\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "\n",
    "    pca = PCA()\n",
    "    scores = pca.fit_transform(Xs)\n",
    "\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        index=X.columns,\n",
    "        columns=[f\"PC{i+1}\" for i in range(pca.n_components_)]\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "    plt.xlabel(\"Components\")\n",
    "    plt.ylabel(\"Cumulative explained variance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.scatter(scores[:,0], scores[:,1])\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return pca, loadings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc3f4b",
   "metadata": {},
   "source": [
    "## Run full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_list = ['1','2','3','4','5','6','7','8']\n",
    "# df = <your contour feature dataframe>\n",
    "\n",
    "masks = build_center_masks(data_list)\n",
    "df_drift = drift_features_from_masks(masks)\n",
    "\n",
    "plot_drift_diagnostics(df_drift)\n",
    "\n",
    "drift_detected, frac = drift_gate(df_drift)\n",
    "print(f\"Drift detected: {drift_detected} (fraction={frac:.2f})\")\n",
    "\n",
    "if not drift_detected:\n",
    "    print(\"Running PCA...\")\n",
    "    pca, loadings = run_pca(df)\n",
    "    for pc in loadings.columns[:3]:\n",
    "        print(f\"\\nTop contributors to {pc}:\")\n",
    "        print(loadings[pc].abs().sort_values(ascending=False).head(8))\n",
    "else:\n",
    "    print(\"PCA skipped due to drift dominance.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
